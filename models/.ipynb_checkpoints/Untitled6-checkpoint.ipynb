{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import PandasTools\n",
    "from collections import Counter\n",
    "## Carregar dados\n",
    "def carregar_dados():\n",
    "    # Definir caminho do arquivo\n",
    "    file = '../dataset/formats/df_ready_classification.sdf'\n",
    "\n",
    "       # Novo dicionário inicializado a partir de um objeto de mapeamento\n",
    "    sdfInfo = dict(smilesName='SMILES', molColName='ROMol')\n",
    "\n",
    "    # Carregando o arquivo SDF com os dicionarios mapeados\n",
    "    moldf = PandasTools.LoadSDF(file, **sdfInfo)\n",
    "    print('Original data: ', moldf.shape)\n",
    "\n",
    "    # Renomear ROMol\n",
    "    moldf = moldf.rename(columns={'ROMol': 'Mol'})\n",
    "\n",
    "    # Remover moléculas RDKit ausentes\n",
    "    moldf = moldf[pd.notnull(moldf['Mol'])]\n",
    "    if 'StandardizerResult' in moldf.columns:\n",
    "        moldf = moldf.drop(columns='StandardizerResult')\n",
    "\n",
    "    # Colunas\n",
    "    print('Dados mantidos: ', moldf.shape)\n",
    "\n",
    "\n",
    "    moldf['Outcome'] = moldf['bioactivity_class'].replace('active', 1)\n",
    "    moldf['Outcome'] = moldf['bioactivity_class'].replace('inactive', 0)\n",
    "\n",
    "    classes = Counter(moldf['Outcome'])\n",
    "    print('Class labels:', np.unique(classes))\n",
    "  \n",
    "    return moldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:  (4829, 19)\n",
      "Dados mantidos:  (4829, 19)\n",
      "Class labels: [Counter({'active': 2841, 0: 1988})]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4829 entries, 0 to 4828\n",
      "Data columns (total 20 columns):\n",
      " #   Column                               Non-Null Count  Dtype \n",
      "---  ------                               --------------  ----- \n",
      " 0   Unnamed: 0                           4829 non-null   object\n",
      " 1   HD                                   4829 non-null   object\n",
      " 2   HA                                   4829 non-null   object\n",
      " 3   logP                                 4829 non-null   object\n",
      " 4   MW                                   4829 non-null   object\n",
      " 5   lit                                  4829 non-null   object\n",
      " 6   sum                                  4829 non-null   object\n",
      " 7   Unnamed: 0.1                         4829 non-null   object\n",
      " 8   bioactivity_class                    4829 non-null   object\n",
      " 9   molecule_chembl_id                   4829 non-null   object\n",
      " 10  canonical_smiles                     4829 non-null   object\n",
      " 11  Peso Molecular                       4829 non-null   object\n",
      " 12  Número de Doadores de Hidrogênio     4829 non-null   object\n",
      " 13  Número de Aceitadores de Hidrogênio  4829 non-null   object\n",
      " 14  OWPC                                 4829 non-null   object\n",
      " 15  pIC50                                4829 non-null   object\n",
      " 16  ID                                   4829 non-null   object\n",
      " 17  SMILES                               4829 non-null   object\n",
      " 18  Mol                                  4829 non-null   object\n",
      " 19  Outcome                              4829 non-null   object\n",
      "dtypes: object(20)\n",
      "memory usage: 792.3+ KB\n"
     ]
    }
   ],
   "source": [
    "moldf = carregar_dados();\n",
    "moldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from rdkit import Chem\n",
    "from math import floor\n",
    "#Rdkit: coleção de quiminformática e software de aprendizado de máquina escrito em C++ e Python de Código Aberto.\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from collections import Counter\n",
    "\n",
    "def morgan_descriptors(moldf):   \n",
    "    moldf['Outcome'] = moldf['Outcome'].replace('active', 1)\n",
    "    moldf['Outcome'] = moldf['Outcome'].replace('inactive', 0)\n",
    "\n",
    "    classes = Counter(moldf['Outcome'])\n",
    "    print('\\033[1m' + 'Forma do conjunto de treinamento:' + '\\n' + '\\033[0m')\n",
    "    for key, value in classes.items():\n",
    "        print('\\t\\t Classe %d: %d' % (key, value))\n",
    "    print('\\t\\t Número total de compostos: %d' % (len(moldf['Outcome'])))\n",
    "\n",
    "    print('Class labels:', np.unique(classes))\n",
    "    \n",
    "    # Calculando os descritores fingerprints de Harry Morgan (vetores de bits).\n",
    "    def calcfp(mol,funcFPInfo=dict(radius=3, nBits=2048, useFeatures=False, useChirality=False)):\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, **funcFPInfo)\n",
    "        fp = pd.Series(np.asarray(fp))\n",
    "        fp = fp.add_prefix('Bit_')\n",
    "        return fp\n",
    "\n",
    "    # Adicionando os 113 componentes e os 2048 dados referetens aos descritores de Morgan\n",
    "    desc = moldf.Mol.apply(calcfp)\n",
    "    descriptors = desc.columns.difference(moldf.columns).tolist()\n",
    "    desc.shape\n",
    "    \n",
    "    # Moldando o conjunto de treinamento e o conjunto de validação externa\n",
    "    moldf_desc = pd.concat([moldf,desc], axis=1)\n",
    "    balance_data = 'no'\n",
    "\n",
    "    if balance_data == 'yes':\n",
    "        # Equilibre os dados usando 1/2 similaridade e 1/2 aleatória\n",
    "        moldf_desc = BalanceBySim(moldf_desc, 'Outcome', 2)\n",
    "        # Forma de impressão\n",
    "        print('Forma do conjunto de treinamento: %s' % Counter(moldf_desc['Outcome'].loc[moldf_desc['Set'] == 'train']))\n",
    "        print('Forma externa definida: %s' % Counter(moldf_desc['Outcome'].loc[moldf_desc['Set'] == 'ext']))\n",
    "\n",
    "    else:\n",
    "        moldf_desc['Set'] = 'train'\n",
    "        # Forma de impressão\n",
    "        print('Forma do conjunto de treinamento: %s' % Counter(moldf_desc['Outcome'].loc[moldf_desc['Set'] == 'train']))\n",
    "        print('Forma externa definida: %s' % Counter(moldf_desc['Outcome'].loc[moldf_desc['Set'] == 'ext']))\n",
    "    \n",
    "    # Conjunto de treinamento\n",
    "    moldf_train = moldf_desc[(moldf_desc['Set'] == 'train')]\n",
    "    \n",
    "    data_train = {'moldf_desc': moldf_desc, 'moldf_train': moldf_train, 'Y_train': moldf_train['Outcome'].to_numpy(), 'X_train': moldf_train[descriptors]}\n",
    "    return data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mForma do conjunto de treinamento:\n",
      "\u001b[0m\n",
      "\t\t Classe 1: 2841\n",
      "\t\t Classe 0: 1988\n",
      "\t\t Número total de compostos: 4829\n",
      "Class labels: [Counter({1: 2841, 0: 1988})]\n",
      "Forma do conjunto de treinamento: Counter({1: 2841, 0: 1988})\n",
      "Forma externa definida: Counter()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4829, 2048)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = morgan_descriptors(moldf)\n",
    "y = data['Y_train']\n",
    "X = data['X_train']\n",
    "# Aplicando a padronização dos dados de treino para algoritmos sensíveis à escala\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5883205632636157"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifique se o conjunto de dados está balanceado\n",
    "sum(y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os algoritmos e suas respectivas distribuições de hiperparâmetros\n",
    "classifiers = [\n",
    "    {\n",
    "        'name': 'SVM',\n",
    "        'classifier': SVC(probability=True),\n",
    "        'param_dist': {\n",
    "            'C': np.logspace(-3, 3, 7),\n",
    "            'kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Random Forest',\n",
    "        'classifier': RandomForestClassifier(),\n",
    "        'param_dist': {\n",
    "            'n_estimators': [50, 100, 150],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'Multilayer Perceptron',\n",
    "        'classifier': MLPClassifier(),\n",
    "        'param_dist': {\n",
    "            'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
    "            'alpha': np.logspace(-5, 3, 9),\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir métricas para avaliação\n",
    "metrics = {\n",
    "    'roc_auc': roc_auc_score,\n",
    "    'confusion_matrix': confusion_matrix,\n",
    "    'accuracy': accuracy_score,\n",
    "    'precision': precision_score,\n",
    "    'recall': recall_score,\n",
    "    'f1': f1_score,\n",
    "    'cohen_kappa': cohen_kappa_score,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir número de splits para a validação cruzada aninhada\n",
    "num_splits_outer = 5\n",
    "num_splits_inner = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicialização da validação cruzada aninhada\n",
    "\n",
    "# Definindo a estratégia de validação cruzada aninhada usando StratifiedKFold com 5 divisões, embaralhamento\n",
    "# dos dados e semente aleatória para reprodutibilidade\n",
    "cv_outer = StratifiedKFold(n_splits=num_splits_outer, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: SVM\n",
      "Validação cruzada aninhada: SVM\n",
      "Best Parameters: {'kernel': 'rbf', 'C': 100.0}\n",
      "Validação cruzada aninhada: SVM\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24073/454299140.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Realização da pesquisa aleatória de hiperparâmetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mrandomized_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Seleção do melhor modelo e parâmetros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1633\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Loop através de cada classificador para treinamento e avaliação\n",
    "for classifier_info in classifiers:\n",
    "    print(f\"Classifier: {classifier_info['name']}\")\n",
    "    \n",
    "    # Inicialização da pesquisa aleatória de hiperparâmetros\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        classifier_info['classifier'], \n",
    "        param_distributions=classifier_info['param_dist'], \n",
    "        n_iter=10, \n",
    "        scoring='roc_auc', \n",
    "        n_jobs=-1, \n",
    "        cv=cv_outer, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Listas para armazenar probabilidades previstas e rótulos reais\n",
    "    y_probs_list = []\n",
    "    y_tests_list = []\n",
    "    y_randomization_list = []\n",
    "    auc_scores = []\n",
    "\n",
    "    \n",
    "    # Loop através das divisões da validação cruzada aninhada\n",
    "    for train_idx, test_idx in cv_outer.split(X, y):\n",
    "        \n",
    "        print(f\"Validação cruzada aninhada: {classifier_info['name']}\")\n",
    "        \n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Realização da pesquisa aleatória de hiperparâmetros\n",
    "        randomized_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Seleção do melhor modelo e parâmetros\n",
    "        best_classifier = randomized_search.best_estimator_\n",
    "        best_params = randomized_search.best_params_\n",
    "        \n",
    "        # Salvar o melhor modelo em um arquivo .pkl\n",
    "        model_filename = f\"best_model_{classifier_info['name']}.pkl\"\n",
    "        joblib.dump(best_classifier, model_filename)\n",
    "        \n",
    "        # Previsão de probabilidades e extensão das listas\n",
    "        y_probs = best_classifier.predict_proba(X_test)[:, 1]\n",
    "        y_probs_list.extend(y_probs)\n",
    "        y_tests_list.extend(y_test)\n",
    "        \n",
    "        # Simulação de y_randomization (substituir por lógica real de randomização)\n",
    "        y_randomization = np.random.permutation(y_test)\n",
    "        y_randomization_list.extend(y_randomization)\n",
    "        \n",
    "        # Calcular métricas de interesse\n",
    "        auc = roc_auc_score(y_test, y_probs)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "        print(f\"Best Parameters: {best_params}\")\n",
    "    \n",
    "    # Avaliação utilizando as métricas\n",
    "    for metric_name, metric_func in metrics.items():\n",
    "        print(f\"Metric: {metric_name}\")\n",
    "        y_pred = np.round(y_probs_list)\n",
    "        \n",
    "        if metric_name == 'roc_auc':\n",
    "            score = metric_func(y_tests_list, y_probs_list)\n",
    "            # Plotagem da curva ROC\n",
    "            fpr, tpr, _ = roc_curve(y_tests_list, y_probs_list)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver Operating Characteristic')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()\n",
    "            \n",
    "        elif metric_name == 'confusion_matrix':\n",
    "            cm = metric_func(y_tests_list, y_pred)\n",
    "            # Plotagem da matriz de confusão\n",
    "            plt.figure()\n",
    "            plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "            plt.title(\"Confusion Matrix\")\n",
    "            plt.colorbar()\n",
    "            tick_marks = np.arange(len(np.unique(y_tests_list)))\n",
    "            plt.xticks(tick_marks, np.unique(y_tests_list))\n",
    "            plt.yticks(tick_marks, np.unique(y_tests_list))\n",
    "            plt.xlabel(\"Predicted\")\n",
    "            plt.ylabel(\"True\")\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            score = metric_func(y_tests_list, y_pred)\n",
    "        \n",
    "        print(f\"Score: {score}\")\n",
    "    \n",
    "    # Plot y_randomization histogram\n",
    "    plt.figure()\n",
    "    plt.hist(y_randomization_list, bins=2, color='blue', alpha=0.7, label='Randomized')\n",
    "    plt.hist(y_tests_list, bins=2, color='red', alpha=0.7, label='Actual')\n",
    "    plt.xlabel('Class Labels')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('y_randomization vs Actual')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calcular estatísticas das métricas\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    variance_auc = np.var(auc_scores)\n",
    "    std_deviation_auc = np.std(auc_scores)\n",
    "\n",
    "    print(f\"Mean AUC: {mean_auc}\")\n",
    "    print(f\"Variance AUC: {variance_auc}\")\n",
    "    print(f\"Standard Deviation AUC: {std_deviation_auc}\")\n",
    "    \n",
    "    print(\"----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
